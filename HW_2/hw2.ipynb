{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDREvPHN31R5"
      },
      "source": [
        "# Αναγνώριση Προτύπων Μηχανικής Μάθησης\n",
        "Εργασία 2 \\\\\n",
        "Χρήστος Μπριστογιάννης sdi1900129 \\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWL0Zkcd4BrI"
      },
      "source": [
        "##Ερώτημα 1: Αναγνώριση Προσώπων (Face recognition)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7mOvc644utO"
      },
      "source": [
        "###Ζητούμενα i\n",
        "Να γράψετε μία συνάρτηση loadImages(path, set_number) η οποία παίρνει ως είσοδο το\n",
        "path στο οποίο βρίσκεται ο φάκελος των εικόνων π.χ. loadImages(“C:/images”, “Set_1”),\n",
        "διαβάζει τις εικόνες και επιστέφει έναν πίνακα δεδομένων ανάλογα με το set_number,\n",
        "όπου κάθε εικόνα αναπαρίσταται ως διάνυσμα στήλη. Η συνάρτηση επιστέφει επίσης τις\n",
        "κατηγορίες (labels) στις οποίες ανήκουν οι διαφορετικές εικόνες κωδικοποιημένες με\n",
        "ακεραίους (π.χ. 0 για φωτογραφίες που ανήκουν στο person_0, 1 για τις φωτογραφίες\n",
        "που ανήκουν στο person_1 κτλ)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzbiDmjwQJTG",
        "outputId": "4e3d3d50-38ea-41d6-9783-d4994e2d7435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def loadImages(path, set_number):\n",
        "  if set_number == \"Set_1\":\n",
        "    start = 1\n",
        "    end = 7\n",
        "  elif set_number == \"Set_2\":\n",
        "    start = 8\n",
        "    end = 19\n",
        "  elif set_number == \"Set_3\":\n",
        "    start = 20\n",
        "    end = 31\n",
        "  elif set_number == \"Set_4\":\n",
        "    start = 32\n",
        "    end = 45\n",
        "  elif set_number == \"Set_5\":\n",
        "    start = 46\n",
        "    end = 64\n",
        "  else:\n",
        "    print(\"Error\")\n",
        "    return\n",
        "\n",
        "  arr = []\n",
        "  labels = []\n",
        "  for i in range(1, 11, 1):\n",
        "    for j in range(start, end+1, 1):\n",
        "      if i == 10:\n",
        "        mes = 'person10'+'_'\n",
        "      else:\n",
        "        mes = 'person0'+str(i)+'_'\n",
        "      if j < 10:\n",
        "        mes = mes+'0'+str(j)\n",
        "      else:\n",
        "        mes = mes + str(j)\n",
        "\n",
        "      img = cv2.imread(path+ mes + '.png', 0)\n",
        "\n",
        "      arr.append(np.reshape(img,-1))\n",
        "      labels.append(i)\n",
        "  return arr, labels\n",
        "\n",
        "\n",
        "#load images\n",
        "numberOfSets = 5\n",
        "nmsset = [\"Set_1\", \"Set_2\", \"Set_3\", \"Set_4\", \"Set_5\"]\n",
        "imgset = [None] * numberOfSets\n",
        "lblset = [None] * numberOfSets\n",
        "path = '/content/drive/My Drive/faces/'\n",
        "\n",
        "for i in range(0, numberOfSets):\n",
        "  imgset[i], lblset[i] = loadImages(path, nmsset[i])\n",
        "  # print(imgset[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N02DiqbT3zuj"
      },
      "source": [
        "###Ζητούμενα ii\n",
        "Να εκπαιδεύσετε την μέθοδο Eigenfaces με d = 9 και d = 30 χρησιμοποιώντας όλες τις\n",
        "εικόνες στο Set_1 (70 εικόνες) και να αναγνωρίσετε τα πρόσωπα στα Set_1 έως Set_5.\n",
        "Για κάθε Set και κάθε τιμή της διάστασης d να αναφέρετε την ακρίβεια ταξινόμησης. Για\n",
        "το Set_1 αναμένουμε 100% ακρίβεια ταξινόμησης καθώς χρησιμοποιήθηκε για την\n",
        "εκπαίδευση της μεθόδου Eigenfaces. Σχολιάστε την δυνατότητα γενίκευσης της μεθόδου\n",
        "στα διαφορετικά Sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI1hWSc3BiRt"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "n_components = 9 ## how may componets to keep\n",
        "pca = PCA(n_components=n_components, whiten=True).fit(imgset[4])\n",
        "\n",
        "print (\"\\n--pca--\\n\",pca)\n",
        "\n",
        "\n",
        "components = pca.transform(imgset[4]) ## tranform the data to the new axes system)\n",
        "print (\"components.shape\",components.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1f-TiMJVouw"
      },
      "source": [
        "##Ερώτημα 2: Ταξινόμηση εικόνων χρησιμοποιώντας SVMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLJPkCU1oeZB",
        "outputId": "e90d623d-21ba-416f-b53f-aecfa23fe4ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Φόρτωσει δεδομένων\n",
        "mnist = fetch_openml('mnist_784')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NAQ2ONH3Vxh1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Μετατρέπουμε τις εικόνες σε μορφή διανύσματος διαστάσεων 28 x 28\n",
        "X = np.array(mnist.data)\n",
        "Y = np.array(mnist.target)\n",
        "X = X.reshape(-1, 28, 28)\n",
        "\n",
        "# Κανονικοποιούμε τα δεδομένα στο διάστημα [0,1]\n",
        "X = X / 255.0\n",
        "\n",
        "# Η συνάρτηση δέχεται τα δεδομένα data labels και τον τρόπο που θέλει να χωρίστουν τα set μεταξύ τους\n",
        "# ανακατεύει την λίστα ώστε να μην έχουμε πάντα τα ίδια set μετά τα διασπάει σύμφωνα με sizes που δέχεται\n",
        "# και μετά επιστρέφει 6 λίστες data και labels\n",
        "def split_shuffle_dataset(data, labels, train_size, val_size, test_size):\n",
        "  \n",
        "  # Ένωση ανακάτεμα και διάσπαση λιστών data και labels\n",
        "  combined = list(zip(data, labels))  \n",
        "  random.shuffle(combined)\n",
        "  shuffled_data, shuffled_labels = zip(*combined)\n",
        "\n",
        "  # Διάσπαση νέων λιστών σε κομμάτια\n",
        "  trainData = np.array(shuffled_data[:train_size])\n",
        "  trainLbl = np.array(shuffled_labels[:train_size])\n",
        "  valData = np.array(shuffled_data[train_size:train_size + val_size])\n",
        "  valLbl = np.array(shuffled_labels[train_size:train_size + val_size])\n",
        "  testData = np.array(shuffled_data[train_size + val_size:])\n",
        "  testLbl = np.array(shuffled_labels[train_size + val_size:])\n",
        "\n",
        "  return trainData, trainLbl, valData, valLbl, testData, testLbl\n",
        "\n",
        "# Έτοιμες λίστες\n",
        "trainData, trainLbl, valData, valLbl, testData, testLbl = split_shuffle_dataset(X, Y, 10000, 5000, 5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5l01L76ya7Z",
        "outputId": "e34e8f11-82be-4e81-e6d0-2976087f6943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing linear kernel...\n",
            "Best hyperparameters for linear kernel: C=0.1, gamma=0.001 and average execution time 6.147791147232056\n",
            "Validation accuracy: 0.9286\n",
            "Test accuracy: 0.9288\n",
            "\n",
            "Testing rbf kernel...\n",
            "Best hyperparameters for rbf kernel: C=100, gamma=0.01 and average execution time 39.545528411865234\n",
            "Validation accuracy: 0.9660\n",
            "Test accuracy: 0.9651\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "kernel_values = ['linear', 'rbf']\n",
        "c_values = [ 0.1, 1, 10, 100]\n",
        "gamma_values = [ 0.001, 0.01, 0.1, 1]\n",
        "sum_execution = 0\n",
        "\n",
        "\n",
        "for kernel in kernel_values:\n",
        "    best_accuracy = 0\n",
        "    best_c = None\n",
        "    best_gamma = None\n",
        "    \n",
        "    print(f'Testing {kernel} kernel...')\n",
        "\n",
        "    for c in c_values:\n",
        "        for gamma in gamma_values:\n",
        "\n",
        "            # SVM train\n",
        "            svm_model = svm.SVC(kernel=kernel, C=c, gamma=gamma)\n",
        "\n",
        "            start_time = time.time()\n",
        "            svm_model.fit(trainData.reshape(trainData.shape[0], -1), trainLbl)\n",
        "            execution_time = time.time() - start_time\n",
        "            sum_execution += execution_time\n",
        "            \n",
        "            # Έλενχος SVM στο validation set\n",
        "            val_predictions = svm_model.predict(valData.reshape(valData.shape[0], -1))\n",
        "            val_accuracy = accuracy_score(valLbl, val_predictions)\n",
        "            \n",
        "            #print(f' for values C={c} and gamma={gamma} the accuracy is {val_accuracy} and execution time is {execution_time}')\n",
        "            \n",
        "            # Εύρεση καλύτερου accuracy υπερπαραμέτρων\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                best_c = c\n",
        "                best_gamma = gamma\n",
        "\n",
        "    # Έλενχος SVM στο  Validation set με τις καλύτερες παραμέτρους\n",
        "    svm_model = svm.SVC(kernel=kernel, C=best_c, gamma=best_gamma)\n",
        "    svm_model.fit(trainData.reshape(trainData.shape[0], -1), trainLbl)\n",
        "\n",
        "    # Έλενχος SVM στο Test set με τις καλύτερες παραμέτρους\n",
        "    test_predictions = svm_model.predict(testData.reshape(testData.shape[0], -1))\n",
        "    test_accuracy = accuracy_score(testLbl, test_predictions)\n",
        "\n",
        "    # Εκτύπωση αποτελέσμάτων και για τα δύο kernel\n",
        "    print(f'Best hyperparameters for {kernel} kernel: C={best_c}, gamma={best_gamma} and average execution time {sum_execution/(len(c_values)*len(gamma_values))}')\n",
        "    print(f'Validation accuracy: {best_accuracy:.4f}')\n",
        "    print(f'Test accuracy: {test_accuracy:.4f}\\n')\n",
        "    sum_execution = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FTPaBxA-LU_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0905f3b-572b-4fca-9771-0c10aa9199cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing PCA with variance ratio 0.5...\n",
            "Number of components: 11\n",
            "Validation accuracy: 0.9342\n",
            "Test accuracy: 0.9304\n",
            "Execution time: 1.1545 seconds\n",
            "\n",
            "Testing PCA with variance ratio 0.8...\n",
            "Number of components: 43\n",
            "Validation accuracy: 0.9652\n",
            "Test accuracy: 0.9662\n",
            "Execution time: 1.3266 seconds\n",
            "\n",
            "Testing PCA with variance ratio 0.95...\n",
            "Number of components: 152\n",
            "Validation accuracy: 0.9670\n",
            "Test accuracy: 0.9653\n",
            "Execution time: 2.7512 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 3 διαφορετικές τιμές για τη διατηρούμενη διακύμανση\n",
        "variance_ratios = [ 0.5, 0.8, 0.95]\n",
        "\n",
        "# PCA και SVM για κάθε variance_ratio με τις καλύτερες παραμέτρους\n",
        "for variance_ratio in variance_ratios:\n",
        "    print(f'Testing PCA with variance ratio {variance_ratio}...')\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA(n_components=variance_ratio)\n",
        "    pca_trainData = pca.fit_transform(trainData.reshape(trainData.shape[0], -1))\n",
        "    pca_valData = pca.transform(valData.reshape(valData.shape[0], -1))\n",
        "    pca_testData = pca.transform(testData.reshape(testData.shape[0], -1))\n",
        "    components = pca.n_components_\n",
        "\n",
        "    # SVM με καλύτερες παραμέτρους\n",
        "    svm_model = svm.SVC(kernel=kernel, C=best_c, gamma=best_gamma)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    svm_model.fit(pca_trainData, trainLbl)\n",
        "    execution_time = time.time() - start_time\n",
        "\n",
        "    # Έλενχος SVM στο Validation set μετά απο pca\n",
        "    val_predictions = svm_model.predict(pca_valData)\n",
        "    val_accuracy = accuracy_score(valLbl, val_predictions)\n",
        "\n",
        "    # Έλενχος SVM στο Test set μετά απο pca\n",
        "    test_predictions = svm_model.predict(pca_testData)\n",
        "    test_accuracy = accuracy_score(testLbl, test_predictions)\n",
        "\n",
        "    print(f'Number of components: {components}')\n",
        "    print(f'Validation accuracy: {val_accuracy:.4f}')\n",
        "    print(f'Test accuracy: {test_accuracy:.4f}')\n",
        "    print(f'Execution time: {execution_time:.4f} seconds\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "D7mOvc644utO",
        "N02DiqbT3zuj"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}